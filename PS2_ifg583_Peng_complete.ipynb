{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning-based Sentiment Analysis of Tweets                \n",
    "## Yahui Peng\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "You are a data scientist working for the government. You want to understand the public opinion regarding hurricane Maria which is responsible for killing at least 499 people in Puerto Rico. Total losses are estimated at $94.4 billion dollars which accrued to government agencies, businesses, and more importantly, familes [1]. With this background, whether you are a politician, bussiness person, or one effected by the hurricane, understanding the sentiment of the general populace is important. For this assigment, you will use a subset of the tweets retrieved from Twitter that mentioned #PuertoRico over the period of October 4 to November 7, 2017 [2] to measure the sentiment (i.e., the \"good\" or \"bad\" opinions people have about the hurricane and its impact) of this event.\n",
    "\n",
    "For this task, we will write code for a lexicon-based analysis (i.e., lexicon-based classification). Lexicon-based classification is a way to categorize text based using manually generated lists of topical words. Essentially, we just need to check if the topical words appear in a piece of text (e.g., a tweet). In this exercise we will make use of manually curated sentiment words. However, the basic experimental process is the same for other tasks (e.g., identifying offensive language).\n",
    "\n",
    "If you are interested, though it is not needed, you can learn more about lexicon-based classification in Chapter 21 (21.2 and 21.6) of the free online book at the following link: [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/21.pdf)\n",
    "\n",
    "### References\n",
    "[1]  Spalding, Rebecca (November 13, 2017). \"Puerto Rico Seeks $94 Billion in Federal Aid for Hurricane Recovery\". Bloomberg News. Retrieved December 15, 2017.\n",
    "\n",
    "[2]  site: https://archive.org/details/puertorico-tweets\n",
    "\n",
    "## Submission Instructions\n",
    "\n",
    "After completing the exercises below, generate a pdf of the code **with** outputs. After that create a zip file containing both the completed exercise and the generated PDF/HTML. You are **required** to check the PDF/HTML to make sure all the code **and** outputs are clearly visible and easy to read. If your code goes off the page, you should reduce the line size. I generally recommend not going over 80 characters.\n",
    "\n",
    "For this task, unzip and move the file \"puerto-rico.jsonl\" in to the same directory as this notebook, then complete the following exercises. However, when you turn the assigment in, do **NOT** include puerto-rico.jsonl in your zip file when you submit the homework, you will kill Blackboard.\n",
    "\n",
    "Finally, name the zip file using a combination of your the assigment and your name, e.g., ps2_zanella.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1 \n",
    "\n",
    "The files \"positive_words.txt\" and \"negative_words.txt\" contain manually curated positive (e.g., good, great, awesome) and negative words (e.g., bad, hate, terrible). The files contain one word on each line. Write a function that takes the open file and adds the words (i.e., each line) to a set then returns it.\n",
    "\n",
    "\n",
    "def file_to_set(file):\n",
    "    # Write code here\n",
    "    wordstr = []\n",
    "    for line in file:\n",
    "        wordstr.append(line.strip()) \n",
    "    return set(wordstr) # You should return a set\n",
    "\n",
    "positive_file = open('./positive-words.txt', encoding='utf8')\n",
    "positive_words = file_to_set(positive_file)\n",
    "positive_file.close()\n",
    "\n",
    "negative_file = open('./negative-words.txt', encoding='iso-8859-1') # If you get a weird read error. Let me know. We can change the encoding.\n",
    "negative_words = file_to_set(negative_file)\n",
    "negative_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asserts finished successfully!\n"
     ]
    }
   ],
   "source": [
    "assert(type(positive_words) == type(set()))\n",
    "assert(type(negative_words) == type(set()))\n",
    "assert(len(positive_words) == 2006)\n",
    "assert(len(negative_words) == 4783)\n",
    "assert(('good' in positive_words)  == True)\n",
    "assert(('bad' in negative_words)  == True)\n",
    "assert(('bad' not in positive_words) == True)\n",
    "print(\"Asserts finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2\n",
    "\n",
    "For this exercise, you need to write a function that counts the number of words in a sentence that also appear in a set. For example, given the set set(['good', 'great']) and the sentence \"this is good good good\", the function should return 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentiment_words(sentiment_set, tweet_text, lower):\n",
    "    # Your code here\n",
    "    import re\n",
    "    counts = 0\n",
    "    words = re.findall(r'[a-z]+',tweet_text)\n",
    "    for letter in words:\n",
    "        if letter in sentiment_set:\n",
    "            counts += 1    \n",
    "    return counts #You should return a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asserts finished successfully!\n"
     ]
    }
   ],
   "source": [
    "assert(count_sentiment_words(positive_words, \"this is a good good good class\", True) == 3)\n",
    "assert(count_sentiment_words(positive_words, \"this is a good\\tgood\\tgood class\", True) == 3)\n",
    "assert(count_sentiment_words(positive_words, \"this is a GOOD GOOD good class\", False) == 1)\n",
    "assert(count_sentiment_words(positive_words, \"Python is the best programming language for data science\", True) == 1)\n",
    "assert(count_sentiment_words(negative_words, \"R is bad compared to Python ;)\", True) == 1)\n",
    "print(\"Asserts finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3\n",
    "\n",
    "For this exercise, you will write a function that takes two numbers as input and returns a string. Intuitively, this is a basic classification function for lexicon-based sentiment classification. \n",
    "\n",
    "The function should take as input parameters the the number of positive (num_pos_words) and negative (num_neg_words) words in each tweet to predict sentiment. If the number of positive words is greater than to the number of negative tweets (num_pos_words > num_neg_words), then predict **\"positive\"**. If the number of negative words is greater than the number of positive words (num_neg_words > num_pos_words), then predict **\"negative\"**. If both num_pos_words and num_neg_words are equal (num_neg_words = num_pos_words), predict **\"neutral\"**. This is known as lexicon-based classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(num_pos_words, num_neg_words):\n",
    "    # Your code here\n",
    "    if num_pos_words > num_neg_words:\n",
    "        prediction = 'positive'\n",
    "    elif num_pos_words < num_neg_words:\n",
    "        prediction = 'negative'\n",
    "    else:\n",
    "        prediction = 'neutral'\n",
    "    return prediction # You should return a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert finished successfully!\n"
     ]
    }
   ],
   "source": [
    "assert(predict(2, 5) == 'negative')\n",
    "assert(predict(5, 2) == 'positive')\n",
    "assert(predict(3, 3) == 'neutral')\n",
    "print(\"Assert finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4\n",
    "\n",
    "This exercise is similar to Exercise 3. However, instead of making a prediction, we should write a function that returns a sentiment score. Specifically, assume num_pos_words is 3 and num_neg_words is 4, the function should return -1. The idea is that the more *positive* the number, the more positive the sentiment. Likewise, the more *negative* the number, the more negative the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(num_pos_words, num_neg_words):\n",
    "    # Your code here\n",
    "    score = num_pos_words - num_neg_words\n",
    "    return score # You should return a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asserts finished successfully!\n"
     ]
    }
   ],
   "source": [
    "assert(predict_score(3, 1) == 2)\n",
    "assert(predict_score(2, 2) == 0)\n",
    "assert(predict_score(2, 5) == -3)\n",
    "print(\"Asserts finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5\n",
    "\n",
    "Write a function that takes a json string as input and returns a Python object. Hint: This can be one line. You can use the json library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_string_to_dictionary(json_string):\n",
    "    # Your code here\n",
    "    mystr = json.loads(json_string)\n",
    "    return mystr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert finished successfully!\n"
     ]
    }
   ],
   "source": [
    "data = json_string_to_dictionary('{\"a\": 1}')\n",
    "assert(data == {'a': 1})\n",
    "data = json_string_to_dictionary('[1,2,3]')\n",
    "assert(data == [1,2,3])\n",
    "print(\"Assert finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 6\n",
    "\n",
    "For this task, we combine the functions written for the previous exercises to classify all of the tweets in a real Twitter dataset. You should write code that does the following:\n",
    "1. Keeps track of the number of tweets\n",
    "2. Keeps track of the number of positive and negative tweets\n",
    "3. Keeps track of the user that tweets the most\n",
    "4. Keeps track of the total number of unique users\n",
    "5. Keeps track of the average number of tweets per user (how many tweets does each user make, on average)\n",
    "6. Keeps track of the most positive and negative tweets.\n",
    "\n",
    "Note: This task depends on Exercises 1 through 5. You will need to complete them first. Also, do **not** store all of the tweets in a list.  This will use too much memory because of the size of the dataset. It is okay to store all of the user's screen names.\n",
    "\n",
    "Finally, the dataset is big! So, I recommend working on a subset of the dataset to make sure your code works, i.e., you could \"break\" after the first 100 lines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_tweets = 0\n",
    "total_number_of_positive_tweets = 0\n",
    "total_number_of_negative_tweets = 0\n",
    "most_positive_tweet = ''\n",
    "most_negative_tweet = ''\n",
    "user_with_most_tweets = ''\n",
    "average_number_tweets_per_user = 0\n",
    "total_number_of_users = 0\n",
    "users = []\n",
    "max_score, min_score = 0, 0\n",
    "\n",
    "# NOTE: You may need to define extra variables to help generate the required output.\n",
    "\n",
    "twitter_dataset = open('tweets_ps2.jsonl', 'r')\n",
    "\n",
    "for row in twitter_dataset:\n",
    "    tweet_dict = json_string_to_dictionary(row)\n",
    "    \n",
    "    ###############################\n",
    "    \n",
    "    tweet_text = tweet_dict['full_text'] # MODIFY THIS LINE TO GET THE \"full_text\" from the tweet_dict\n",
    "    screen_name = tweet_dict['user']['screen_name'] # MODIFY THIS LINE TO GET THE \"screen_name\" from the tweet_dict\n",
    "    ###############################\n",
    "    \n",
    "    num_pos_words = count_sentiment_words(positive_words, tweet_text, True)\n",
    "    num_neg_words = count_sentiment_words(negative_words, tweet_text, True)\n",
    "    \n",
    "    sentiment_prediction = predict(num_pos_words, num_neg_words)\n",
    "    sentiment_score = predict_score(num_pos_words, num_neg_words)\n",
    "    \n",
    "    ################################\n",
    "    # Your code should do the following:\n",
    "    #   1. Keep track of the number of tweets\n",
    "    #   2. Keep track of the number of positive and negative tweets\n",
    "    #   3. Keep track of the user that tweet the most\n",
    "    #   4. Keep track of the total number of unique users\n",
    "    #   5. Keep track of the average number of tweets per user (how many tweets does each user make, on average)\n",
    "    #   6. Keep track of the most positive and negative tweets.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    total_number_of_tweets += 1\n",
    "    if sentiment_prediction == 'positive':\n",
    "        total_number_of_positive_tweets += 1\n",
    "    elif sentiment_prediction == 'negative':\n",
    "        total_number_of_negative_tweets += 1    \n",
    "    all_users = users.append(screen_name)\n",
    "    if sentiment_score > max_score:\n",
    "        max_score = sentiment_score\n",
    "        most_positive_tweet = tweet_text\n",
    "    elif sentiment_score < min_score:\n",
    "        min_score = sentiment_score\n",
    "        most_negative_tweet = tweet_text\n",
    "    ################################\n",
    "\n",
    "# You may need to have code after the for loop, depending on your implementation\n",
    "# CODE HERE (Maybe, depending on your implementation)\n",
    "total_number_of_users = len(set(users))\n",
    "average_number_tweets_per_user = total_number_of_tweets/total_number_of_users\n",
    "user_with_most_tweets = max(set(users), key=users.count)\n",
    "\n",
    "twitter_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Tweets: 8100\n",
      "Total Number of Positive Tweets: 1946\n",
      "Total Number of Negative Tweets: 2203\n",
      "\n",
      "Most Positive Tweet\n",
      "RT @Dr_Woga: I am so delighted on these proud women.\n",
      "\n",
      "#PuertoRico #resist #Science #atheist #Impeach45   #free #tech #MAGA #trump #win #rt…\n",
      "\n",
      "Most Negative Tweet\n",
      "RT @TheDailyEdge: Trump says he's working really hard on #PuertoRico. He's either useless or a liar. Or a useless liar. https://t.co/dr8wLa…\n",
      "\n",
      "Total Number of Users: 7512\n",
      "Average Number of Tweets per User: 1.0782747603833867\n",
      "User with the most tweets: Noti_PuertoRico\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Number of Tweets: {}\".format(total_number_of_tweets))\n",
    "print(\"Total Number of Positive Tweets: {}\".format(total_number_of_positive_tweets))\n",
    "print(\"Total Number of Negative Tweets: {}\\n\".format(total_number_of_negative_tweets))\n",
    "\n",
    "print(\"Most Positive Tweet\")\n",
    "print(most_positive_tweet)\n",
    "print()\n",
    "\n",
    "print(\"Most Negative Tweet\")\n",
    "print(most_negative_tweet)\n",
    "print()\n",
    "\n",
    "print(\"Total Number of Users: {}\".format(total_number_of_users))\n",
    "print(\"Average Number of Tweets per User: {}\".format(average_number_tweets_per_user))\n",
    "print(\"User with the most tweets: {}\".format(user_with_most_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below give example inputs and correct outputs using asserts, and can be run to test the code. Passing these tests is necessary, but **NOT** sufficient to guarantee your implementation is correct. You may add additional test cases, but do not remove any tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assert finished successfully!\n"
     ]
    }
   ],
   "source": [
    "assert(isinstance(total_number_of_tweets, int) or isinstance(total_number_of_tweets, float))\n",
    "assert(isinstance(total_number_of_positive_tweets, int) or isinstance(total_number_of_positive_tweets, float))\n",
    "assert(isinstance(total_number_of_negative_tweets, int) or isinstance(total_number_of_negative_tweets, float))\n",
    "assert(isinstance(most_positive_tweet, str))\n",
    "assert(isinstance(most_negative_tweet, str))\n",
    "assert(isinstance(user_with_most_tweets, str))\n",
    "assert(total_number_of_tweets == 8100)\n",
    "print(\"Assert finished successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 7\n",
    "\n",
    "For this exercise, you will perform manual analysis of the predictions. Modify the code to load the tweet text, then answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1: RT @daddy_yankee: I know the reconstruction of my home island will requiere long-term solutions. - go to the link and help me raise more mo…\n",
      "Tweet 1 Prediction: neutral\n",
      "\n",
      "Tweet 2: RT @daddy_yankee: I know the reconstruction of my home island will requiere long-term solutions. - go to the link and help me raise more mo…\n",
      "Tweet 2 Prediction: neutral\n",
      "\n",
      "Tweet 3: RT @USNavy: #USNSComfort arrives in #SanJuan, #PuertoRico to support Hurricane #Maria relief - https://t.co/wkKaHc1LD2 @potus @fema @ricard…\n",
      "Tweet 3 Prediction: positive\n",
      "\n",
      "Tweet 4: PACKED at @MoMAPS1 before star-studded #PuertoRico fundraiser w/ @JimmyVanBramer @popdemoc + more! https://t.co/fcBt5uqfym\n",
      "Tweet 4 Prediction: neutral\n",
      "\n",
      "Tweet 5: RT @ExDemLatina: .@CarmenYulinCruz is a Lying policial Corrupt hack! \n",
      "She has time to make another shirt for media rounds. #PuertoRico #San…\n",
      "Tweet 5 Prediction: negative\n",
      "\n",
      "Tweet 6: RT @MStrooo6: Just trying to do my part. Please help me in my efforts to raise money for Puerto Rico! All donations help! 🇵🇷\n",
      "\n",
      "https://t.co/…\n",
      "Tweet 6 Prediction: neutral\n",
      "\n",
      "Tweet 7: RT @pdacosta: Patients eating dog food in #PuertoRico clinics as despair rises, @CNN reports\n",
      "Tweet 7 Prediction: negative\n",
      "\n",
      "Tweet 8: Trump afirma que la deuda de #PuertoRico tendrá que ser liquidada https://t.co/sSNgyzSH2Y\n",
      "Tweet 8 Prediction: neutral\n",
      "\n",
      "Tweet 9: RT @daddy_yankee: We are on the ground delivering Food helping our people in #PuertoRico this weekend, Toa Baja, Morovis , Orocovis.  🙏🏻🇵🇷@…\n",
      "Tweet 9 Prediction: positive\n",
      "\n",
      "Tweet 10: Rex Tillerson was wrong. #Trump is not a moron. Morons are way smarter and far more compassionate. #PuertoRico deserves better. We all do. https://t.co/nBglI0gudL\n",
      "Tweet 10 Prediction: positive\n",
      "\n",
      "Tweet 11: Banco de Desarrollo Económico ofrece moratoria automática de 60 días https://t.co/Z4maUoh24E https://t.co/OoRkPmfKBi …\n",
      "Tweet 11 Prediction: neutral\n",
      "\n",
      "Tweet 12: RT @RONTHINKblog: Also shameful =&gt; @RepJenniffer This GOP suck-up stood next to Trump as he tossed rolls of paper towel to her constituents…\n",
      "Tweet 12 Prediction: negative\n",
      "\n",
      "Tweet 13: RT @MKRIZSA50: #Carter\n",
      "#Bush41\n",
      "#Clinton\n",
      "#Bush43\n",
      "#Obama\n",
      "🇺🇸❤️🇺🇸\n",
      "#Texas #Florida #PuertoRico #USVirginIslands https://t.co/IE52CjkyGi\n",
      "Tweet 13 Prediction: neutral\n",
      "\n",
      "Tweet 14: RT @ericbolling: When will @realDonaldTrump catch a break from fake news outrage? Very unfair slams over #PuertoRico visit.\n",
      "Tweet 14 Prediction: negative\n",
      "\n",
      "Tweet 15: RT @USNavy: #USNSComfort arrives in #SanJuan, #PuertoRico to support Hurricane #Maria relief - https://t.co/wkKaHc1LD2 @potus @fema @ricard…\n",
      "Tweet 15 Prediction: positive\n",
      "\n",
      "Tweet 16: RT @SBALinda: Thank you to @USArmy @USACEHQ for taking the time to speak with me on the #DisasterRecovery efforts here in #PuertoRico. http…\n",
      "Tweet 16 Prediction: neutral\n",
      "\n",
      "Tweet 17: RT @ChicagosMayor: 23 members of the Chicago Fire Department headed to #PuertoRico this morning to assist with relief efforts and bring res…\n",
      "Tweet 17 Prediction: neutral\n",
      "\n",
      "Tweet 18: RT @FoxNews: EXCLUSIVE: @POTUS interview in #PuertoRico \"Now people are really seeing what we've done: The runways are open, the ships are…\n",
      "Tweet 18 Prediction: neutral\n",
      "\n",
      "Tweet 19: RT @MadisonSiriusXM: How inhumane can #Trump be? #PuertoRico has suffered a tremendous tragedy and there is never an appropriate time for s…\n",
      "Tweet 19 Prediction: negative\n",
      "\n",
      "Tweet 20: RT @deysyreportera: @ReliefGang @TRAEABN helping the #Houston #PuertoRico communities https://t.co/n8a7boWmr3\n",
      "Tweet 20 Prediction: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "twitter_dataset = open('tweets_ps2.jsonl', 'r')\n",
    "\n",
    "num_tweets_to_print = 20\n",
    "\n",
    "num_tweets = 0\n",
    "\n",
    "for row in twitter_dataset:\n",
    "    num_tweets += 1\n",
    "    tweet_dict = json_string_to_dictionary(row)\n",
    "    \n",
    "    ###############################\n",
    "    # YOUR CODE HERE\n",
    "    tweet_text = tweet_dict['full_text'] # MODIFY THIS LINE TO GET THE \"full_text\" from the tweet_dict    \n",
    "    ###############################\n",
    "    \n",
    "    num_pos_words = count_sentiment_words(positive_words, tweet_text, True)\n",
    "    num_neg_words = count_sentiment_words(negative_words, tweet_text, True)\n",
    "    \n",
    "    sentiment_prediction = predict(num_pos_words, num_neg_words)\n",
    "    \n",
    "    print(\"Tweet {}: {}\".format(num_tweets, tweet_text))\n",
    "    print(\"Tweet {} Prediction: {}\".format(num_tweets, sentiment_prediction))\n",
    "    print()\n",
    "    \n",
    "    if num_tweets == num_tweets_to_print:\n",
    "        break\n",
    "    \n",
    "twitter_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following tasks:\n",
    " \n",
    "- Manually annotate all of the tweets printed above:\n",
    "   1. Tweet 1 Annotation Here  neutral\n",
    "   1. Tweet 2 Annotation Here  neutral\n",
    "   1. Tweet 3 Annotation Here  positive\n",
    "   1. Tweet 4 Annotation Here  neutral\n",
    "   1. Tweet 5 Annotation Here  negative\n",
    "   1. Tweet 6 Annotation Here  neutral\n",
    "   1. Tweet 7 Annotation Here  negative\n",
    "   1. Tweet 8 Annotation Here  neutral\n",
    "   1. Tweet 9 Annotation Here  positive\n",
    "   1. Tweet 10 Annotation Here negative\n",
    "   1. Tweet 11 Annotation Here neutral\n",
    "   1. Tweet 12 Annotation Here negative\n",
    "   1. Tweet 13 Annotation Here neutral\n",
    "   1. Tweet 14 Annotation Here negative\n",
    "   1. Tweet 15 Annotation Here positive\n",
    "   1. Tweet 16 Annotation Here positive\n",
    "   1. Tweet 17 Annotation Here positive\n",
    "   1. Tweet 18 Annotation Here positive\n",
    "   1. Tweet 19 Annotation Here negative\n",
    "   1. Tweet 20 Annotation Here positive\n",
    "\n",
    "- How many of the predictions are right or wrong compared to your annotations?\n",
    "    - Answer here\n",
    "   - Four of the predictions are wrong compared to my annotations, namely tweet 10, 16, 17, and 18.\n",
    "    \n",
    "- Do you see any major limitations of lexicon-based classificaiton (i.e., making sentiment predictions using individual words)? Use your intuition, I will accept most answers, as long as it makes some sense. Please describe and provide examples below:\n",
    "\n",
    "- Answer Here\n",
    "  - Yes, a major limitation of lexicon-based classification is incorrect sentiment scoring of opinion words by the existing lexicons. \n",
    "  - For instance,\n",
    "   - Tweet 10 is predicted to be positive. However, the expression 'Morons are way smarter and far more compassionate.' is sarcastic which delivers negative sentiment. According to the lexicon-based classification, the positive-words includes 'smarter', 'compassionate' and 'better', while the negative-words includes 'moron', resulting in a sentiment score greater than zero.\n",
    "   - Tweet 16 is predicted to be neutral becauses the words 'thank' and 'effort' are not in the positive-words. In fact, the user delivers grateful sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 Comparing Lexicon and RandomForest Classifiers\n",
    "\n",
    "For this exercise, you will use a different dataset already split in train and test. Both *allTrainingData.tsv* and *twitdata_TEST.tsv* include the golden label column. The first cell of code loads the datasets into 4 lists of strings:\n",
    " - X_txt_train  (this are the features for training the classifier)\n",
    " - X_txt_test   (you test the classifier against these features)\n",
    " - y_test       (gold labels for the test dataset)\n",
    " - y_train      (gold labels for the train dataset)\n",
    "\n",
    "You will perform the following tasks:\n",
    "1. Use a Lexicon Classifier (count of positive and negative words ) to classify the tweets in the **test dataset**\n",
    "   - The classification should be *neutral, positive, or negative*\n",
    "   - Calculate the F1 score for the Lexicon Classifier\n",
    "3. Use a different classifier (e.g. RandomForestClassifier) as follows:\n",
    "    - Train the selected classifier using the **train dataset**\n",
    "    - Using the trained classifier, predict the labels for the **test dataset**\n",
    "    - Calculate the F1 score\n",
    "4. Compare the two F1 scores: which one is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8018 3199\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "import csv\n",
    "\n",
    "X_txt_train= []\n",
    "y_train = []\n",
    "X_txt_test= []\n",
    "y_test= []\n",
    "\n",
    "with open('twitdata_TEST.tsv',encoding = 'utf8') as twat:\n",
    "    Twat = csv.reader(twat, delimiter='\\t', quoting = csv.QUOTE_NONE)\n",
    "    header = True\n",
    "    for row in Twat:\n",
    "        if header:\n",
    "            header = False\n",
    "        X_txt_test.append(row[3])\n",
    "        y_test.append(row[2])\n",
    "with open('allTrainingData.tsv',encoding = 'utf8') as BBCtrain:\n",
    "    BBC = csv.reader(BBCtrain, delimiter='\\t',quoting = csv.QUOTE_NONE)\n",
    "    header = True\n",
    "    for row in BBC:\n",
    "        if header:\n",
    "            header = False\n",
    "        X_txt_train.append(row[3])\n",
    "        y_train.append(row[2])\n",
    "print(len(X_txt_train),len(X_txt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and document your code here\n",
    "# Step 1: Lexicon Classifier\n",
    "# write code here\n",
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "        self.positive_words = set()\n",
    "        with open('positive-words.txt', encoding = 'utf-8') as iFile:\n",
    "            for row in iFile:\n",
    "                self.positive_words.add(row.strip())\n",
    "                \n",
    "                \n",
    "\n",
    "        self.negative_words = set()\n",
    "        with open('negative-words.txt', encoding='iso-8859-1') as iFile:\n",
    "            for row in iFile:\n",
    "                self.negative_words.add(row.strip())\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        num_pos_words = 0\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.positive_words:\n",
    "                num_pos_words += 1\n",
    "            elif word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "\n",
    "        pred = 'neutral'\n",
    "        if num_pos_words > num_neg_words:\n",
    "            pred = 'positive'\n",
    "        elif num_pos_words < num_neg_words:\n",
    "            pred = 'negative'\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def count_pos_words(self, sentence):\n",
    "            num_pos_words = 0\n",
    "            for word in sentence.lower().split():\n",
    "                if word in self.positive_words:\n",
    "                    num_pos_words += 1\n",
    "            return num_pos_words\n",
    "        \n",
    "    def count_neg_words(self, sentence):\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in self.negative_words:\n",
    "                num_neg_words += 1\n",
    "        return num_neg_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5827\n",
      "Recall: 0.5827\n",
      "F1: 0.5827\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2 Calculate F1 for the Lexicon Classifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "myLC = LexiconClassifier()\n",
    "lex_test_preds = []\n",
    "for t in X_txt_test:\n",
    "    lex_test_preds.append(myLC.predict(t))\n",
    "precision = precision_score(y_test, lex_test_preds, average=\"micro\")\n",
    "recall = recall_score(y_test, lex_test_preds, average=\"micro\")\n",
    "f1 = f1_score(y_test, lex_test_preds, average=\"micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use a different classifier\n",
    "# Step 2.1 Train the selected classifier using X_txt_train and y_train\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "## Do not change the following 4 lines\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "# WRITE CODE HERE\n",
    "vec = CountVectorizer(ngram_range=(1,1))\n",
    "vec.fit(X_txt_train)\n",
    "X_train = vec.transform(X_txt_train)\n",
    "X_test = vec.transform(X_txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2  Predict the labels for the test dataset X_txt_test\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "svm_test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6114\n",
      "Recall: 0.6114\n",
      "F1: 0.6114\n"
     ]
    }
   ],
   "source": [
    "# Step 2.3 Calculate the F1 score for the selected classifier\n",
    "\n",
    "f1 = f1_score(y_test, svm_test_predictions, average=\"micro\")\n",
    "precision = precision_score(y_test, svm_test_predictions, average=\"micro\")\n",
    "recall = recall_score(y_test, svm_test_predictions, average=\"micro\")\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier has higher F1 score than LexiconClassifier.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compare and discuss the two results. \n",
    "print('RandomForestClassifier has higher F1 score than LexiconClassifier.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
